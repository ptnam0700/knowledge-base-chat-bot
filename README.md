# Thunderbolts - Intelligent Content Analysis & Summarization Application

## ğŸ¯ Project Overview
Thunderbolts is an advanced AI-powered application that provides intelligent analysis and summarization of various content types including videos, audio files, and documents. The application features a sophisticated memory system and uses cutting-edge AI technologies including speech-to-text, natural language processing, vector databases, and large language models.

## ğŸš€ Features
- **Multi-format Support**: Process video, audio, PDF, DOCX, TXT files, and YouTube links
- **Advanced Memory System**: Short-term and long-term memory with conversation tracking
- **Advanced Audio Processing**: Vocal separation, noise reduction, speech enhancement
- **Intelligent Text Processing**: Content analysis, cleaning, chunking, and embedding
- **Semantic Search**: Multi-hop retrieval with reranking capabilities
- **Web Fallback**: Automatic web search when local content is insufficient
- **Multi-modal AI**: Text-to-speech, speech-to-text, image generation (when API configured)
- **Interactive Interface**: User-friendly Streamlit multi-page web application
- **Graceful Fallbacks**: Works even when some dependencies are missing
- **Notebook System**: Organize and manage multiple knowledge collections
- **YouTube Transcript + Description**: yt-dlp metadata/audio with OpenAI Whisper API transcription; video description included in chunks
- **Full i18n UI**: Multi-language interface across Notebooks and Settings with live language switching

## ğŸ”§ Recent Fixes & Improvements (v1.1.0)
- **âœ… Issue #1: Embedding Model Configuration**
  - Fixed online embedding model detection for third-party providers
  - Corrected base URL and API key selection logic
  - Enhanced model name handling for embeddings

- **âœ… Issue #2: Vector Database Persistence**
  - Resolved database data loss after application restart
  - Implemented auto-save functionality
  - Fixed shared database instances between components

- **âœ… Issue #3: LLM Client Provider Detection**
  - Fixed Azure OpenAI parameter handling
  - Implemented automatic third-party provider detection
  - Enhanced provider compatibility and error handling

- **âœ… Issue #4: UI Bug Fixes**
  - Fixed column reference errors in notebook interface
  - Improved error handling in Streamlit components
  - Enhanced user experience and stability

- **âœ… YouTube Processing Enhancements**
  - Updated yt-dlp configuration (User-Agent, retries, 720p fallback) to reduce 403/format errors
  - Robust audio-only download prioritizing m4a/webm without FFmpeg postprocessing (fixes ffprobe codec warnings)
  - Switched transcript generation to OpenAI Whisper API; included video description and transcript in chunking

- **âœ… Internationalization (i18n)**
  - Implemented translation registry for all Streamlit components on Notebooks and Settings
  - Language is saved and applied across pages; Import/Export Settings section localized
  - Fixed sorting to use internal keys independent of translations

- **âœ… Settings Simplification**
  - Removed unused flags: show_processing_time, show_confidence_score, enable_animations
  - Removed local theme selector (use Streamlit global theme)
  - Reordered tabs: Interface â†’ Model â†’ Search â†’ Audio â†’ Memory â†’ Advanced

## ğŸ—ï¸ Architecture
The application follows an Object-Oriented Programming (OOP) design with the following main components:

### Core Modules
1. **Data Processing** (`src/core/`)
   - Audio/Video processing
   - Document text extraction
   - Speech-to-text conversion

2. **Text Analysis** (`src/analysis/`)
   - Content analysis and validation
   - Text cleaning and preprocessing
   - Intelligent chunking strategies

3. **Vector Database** (`src/database/`)
   - FAISS vector storage
   - Embedding generation (OpenAI + Sentence Transformers)
   - Metadata management

4. **Search Engine** (`src/search/`)
   - Semantic search
   - Multi-hop retrieval
   - Reranking algorithms

5. **AI Integration** (`src/ai/`)
   - Azure OpenAI integration
   - OpenAI API support
   - Function calling capabilities
   - Prompt engineering
   - Multi-modal AI features

6. **Web Interface** (`src/interface/`)
   - Streamlit multi-page application
   - Notebook management system
   - File upload handling
   - Result visualization
   - i18n registry (`src/interface/utils/prompt_text.py`) and Settings Manager

7. **Memory System** (`src/utils/memory/`)
   - Short-term and long-term memory
   - Conversation tracking
   - Context management

## ğŸ› ï¸ Technology Stack
- **Audio/Video Processing**: moviepy, ffmpeg-python, whisper, librosa
- **YouTube**: yt-dlp (2025.8.x+) with resilient headers/retries
- **Text Processing**: SpaCy, NLTK, pdfplumber, python-docx, pyvi (Vietnamese)
- **Vector Database**: FAISS, sentence-transformers, ChromaDB
- **AI/ML**: Azure OpenAI, OpenAI API, LangChain, Transformers
- **Web Framework**: Streamlit 1.48.0
- **Package Management**: pip, conda
- **Development Tools**: pytest, black, flake8, mypy

## ğŸ“ Project Structure
```
Thunderbolts_SummarizeApplication/
â”œâ”€â”€ src/                          # Core source code
â”‚   â”œâ”€â”€ ai/                      # AI integration layer
â”‚   â”‚   â”œâ”€â”€ llm_client.py       # LLM client (Azure OpenAI, OpenAI)
â”‚   â”‚   â”œâ”€â”€ multimodal.py       # Multi-modal AI capabilities
â”‚   â”‚   â”œâ”€â”€ tts_client.py       # Text-to-speech client
â”‚   â”‚   â”œâ”€â”€ function_calling.py # Function calling system
â”‚   â”‚   â”œâ”€â”€ prompt_engineer.py  # Advanced prompt management
â”‚   â”‚   â””â”€â”€ summarizer.py       # Content summarization
â”‚   â”œâ”€â”€ analysis/                # Text analysis and processing
â”‚   â”‚   â”œâ”€â”€ text_analyzer.py    # Content analysis
â”‚   â”‚   â”œâ”€â”€ text_cleaner.py     # Text preprocessing
â”‚   â”‚   â””â”€â”€ text_chunker.py     # Intelligent text chunking
â”‚   â”œâ”€â”€ core/                    # Data processing layer
â”‚   â”‚   â”œâ”€â”€ audio_processor.py  # Audio processing
â”‚   â”‚   â”œâ”€â”€ video_processor.py  # Video processing
â”‚   â”‚   â”œâ”€â”€ document_processor.py # Document processing
â”‚   â”‚   â””â”€â”€ speech_to_text.py   # Speech recognition
â”‚   â”œâ”€â”€ database/                # Vector database and storage
â”‚   â”‚   â”œâ”€â”€ vector_database.py  # FAISS vector storage
â”‚   â”‚   â”œâ”€â”€ embedding_generator.py # Text embeddings
â”‚   â”‚   â””â”€â”€ metadata_manager.py # Metadata management
â”‚   â”œâ”€â”€ interface/               # User interface components
â”‚   â”‚   â”œâ”€â”€ app.py              # Main Streamlit app
â”‚   â”‚   â”œâ”€â”€ pages/              # Multi-page navigation
â”‚   â”‚   â”‚   â”œâ”€â”€ 01_Notebooks.py # Notebook management
â”‚   â”‚   â”‚   â””â”€â”€ 04_Settings.py  # Application settings
â”‚   â”‚   â”œâ”€â”€ components.py       # Reusable UI components
â”‚   â”‚   â””â”€â”€ utils/              # Interface utilities
â”‚   â”œâ”€â”€ search/                  # Search and retrieval engine
â”‚   â”‚   â”œâ”€â”€ semantic_search.py  # Semantic search
â”‚   â”‚   â”œâ”€â”€ retrieval_engine.py # Multi-hop retrieval
â”‚   â”‚   â””â”€â”€ web_search.py       # Web search fallback
â”‚   â””â”€â”€ utils/                   # Utility functions and helpers
â”‚       â”œâ”€â”€ logger.py           # Logging system
â”‚       â”œâ”€â”€ memory.py           # Memory management
â”‚       â”œâ”€â”€ cache.py            # Caching system
â”‚       â””â”€â”€ exceptions.py       # Custom exceptions
â”œâ”€â”€ data/                        # Data storage directory
â”‚   â”œâ”€â”€ vectordb/               # Vector database files
â”‚   â”œâ”€â”€ memory/                 # Memory system storage
â”‚   â”œâ”€â”€ cache/                  # General cache storage
â”‚   â”œâ”€â”€ embedding_cache/        # Embedding result cache
â”‚   â”œâ”€â”€ llm_cache/              # LLM response cache
â”‚   â”œâ”€â”€ models/                 # Local AI models
â”‚   â”œâ”€â”€ temp/                   # Temporary files
â”‚   â””â”€â”€ notes/                  # User notes and documents
â”œâ”€â”€ config/                      # Configuration files
â”‚   â””â”€â”€ settings.py             # Application settings
â”œâ”€â”€ tests/                       # Test suite
â”œâ”€â”€ docs/                        # Documentation
â”œâ”€â”€ logs/                        # Application logs
â”œâ”€â”€ requirements.txt             # Python dependencies (239 packages)
â”œâ”€â”€ start_app.py                 # Application startup script
â”œâ”€â”€ main.py                      # Alternative entry point
â”œâ”€â”€ pyproject.toml              # Project configuration
â””â”€â”€ setup.py                     # Package setup
```

## ğŸš€ Getting Started

### Prerequisites
- **Python**: 3.9 or higher (3.11 recommended)
- **Conda**: Environment management
  - Download from: https://adoptium.net/temurin/releases/
- **FFmpeg**: For video/audio processing (optional but recommended)
- **API Credentials**: Azure OpenAI or OpenAI API (optional - app works without them)

### Quick Setup
1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd Thunderbolts_SummarizeApplication
   ```

2. **Create and activate conda environment**
   ```bash
   conda create -n Project_1 python=3.11
   conda activate Project_1
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```
   **Note**: This installs 239 packages including:
   - Core AI: openai, langchain, transformers, sentence-transformers
   - ML/Data: numpy, pandas, scikit-learn, torch
   - Web: streamlit, requests, beautifulsoup4
   - Audio/Video: moviepy, librosa, soundfile
   - Text Processing: spacy, nltk, pdfplumber, python-docx
   - Vector DB: faiss-cpu, chromadb

4. **Configure environment variables (optional)**
   - Copy `.env.example` to `.env`
   - Add your API keys and configuration:
   ```env
   # Azure OpenAI
   AZURE_OPENAI_API_KEY=your_azure_openai_api_key_here
   AZURE_OPENAI_ENDPOINT=https://your-resource-name.openai.azure.com/
   AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4
   
   # OpenAI (fallback)
   OPENAI_API_KEY=your_openai_api_key_here
   OPENAI_BASE_URL=https://api.openai.com/v1
   
   # Google Search (optional)
   GOOGLE_API_KEY=your_google_api_key
   GOOGLE_CSE_ID=your_custom_search_engine_id
   
   # SerpAPI (optional)
   SERPAPI_API_KEY=your_serpapi_key
   ```
   - **Note**: App works without API keys but with limited functionality


6. **Run the application**
   ```bash
   conda activate Project_1
   python start_app.py
   ```
   - Opens Streamlit app at http://localhost:8501
   - Use sidebar navigation to access different pages

### Manual Setup
If you prefer manual setup:

1. **Activate conda environment**
   ```bash
   conda activate Project_1
   ```

2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Download language models**
   ```bash
   conda activate Project_1
   python -m spacy download en_core_web_sm
   # Vietnamese model is included in requirements.txt
   ```

4. **Set up configuration**
   ```bash
   cp .env.example .env
   # Edit .env with your API keys
   ```

5. **Run tests**
   ```bash
   conda activate Project_1
   pytest tests/ -v
   ```

## ğŸ¯ Usage

### Web Interface
1. **Start the application**:
   ```bash
   python start_app.py
   ```
2. **Open browser** to `http://localhost:8501`
3. **Navigate using sidebar**:
   - **Home**: View and manage your notebooks
   - **Create Notebook**: Create a new knowledge collection
   - **Notebook**: View and chat with a specific notebook
   - **Settings**: Configure application parameters

### Supported File Types
- **Video**: MP4, AVI, MOV, MKV, WebM
- **Audio**: MP3, WAV, M4A, FLAC, OGG
- **Documents**: PDF, DOCX, TXT
- **URLs**: YouTube videos, web pages, RSS feeds

### Key Features
- **Multi-format Processing**: Handles video, audio, and text files
- **Intelligent Summarization**: Context-aware summaries with various styles
- **Semantic Search**: Find relevant information across all processed content
- **Multi-modal Output**: Text, audio, and visual summaries
- **Web Search Fallback**: Searches the web when local content is insufficient
- **Source Attribution**: Tracks and cites information sources
- **Memory System**: Short-term and long-term memory for conversation continuity
- **Context Awareness**: Remembers previous interactions and learned facts
- **Notebook Management**: Organize content into themed collections
- **i18n**: Multi-language UI for all pages; change language in Settings â†’ Interface
- **YouTube**: Transcript via OpenAI Whisper API, description included in chunks

## ğŸ”§ Configuration

### Environment Variables
See `.env.example` for all available configuration options:

- **AI Models**: Azure OpenAI, OpenAI API settings
- **Processing**: File size limits, supported formats
- **Search**: Similarity thresholds, result limits
- **Performance**: Caching, batch processing settings
- **Audio**: Sample rates, noise reduction, vocal separation

### Advanced Configuration
Edit `config/settings.py` for advanced customization:
- Model parameters and deployment names
- Processing strategies and chunking settings
- Database settings and vector dimensions
- Performance tuning and resource limits
- YouTube/Whisper and search behavior toggles

## ğŸ§ª Testing
Run the test suite:
```bash
# Run all tests
pytest

# Run specific test categories
pytest tests/test_text_processing.py -v
pytest tests/test_vector_database.py -v

# Run with coverage
pytest --cov=src tests/
```

## ğŸ“Š Performance Optimization

### Caching
The application includes intelligent caching:
- **Embedding Cache**: Reuses embeddings for identical text
- **LLM Response Cache**: Caches AI responses for repeated queries
- **File Processing Cache**: Avoids reprocessing unchanged files
- **Metadata Cache**: Caches document metadata and analysis results

### Memory Management
- Automatic memory optimization and cleanup
- Batch processing for large datasets
- Configurable memory thresholds and retention policies
- LRU eviction for short-term memory

### API Rate Limiting
- Built-in rate limiting for API calls
- Configurable limits per service
- Automatic retry with exponential backoff
- Graceful degradation when APIs are unavailable

## ğŸ” Troubleshooting

### Common Issues
1. **Import Errors**: Ensure conda environment Project_1 is activated
2. **Model Download Failures**: Check internet connection and try manual download
3. **API Errors**: Verify API keys and endpoints in `.env`
4. **Memory Issues**: Reduce batch sizes in configuration
5. **File Processing Errors**: Check file formats and sizes

### Common Issues & Solutions

#### NumPy Compatibility Issues
- **Error**: "A module that was compiled using NumPy 1.x cannot be run in NumPy 2.x"
- **Solution**: Ensure NumPy 1.x is installed:
  ```bash
  conda activate Project_1
  pip install "numpy>=1.24.0,<2.0.0" --force-reinstall
  ```

#### Missing Dependencies
- **Error**: "No module named 'langchain'" or similar
- **Solution**: Ensure you're in the correct conda environment:
  ```bash
  conda activate Project_1
  pip install -r requirements.txt
  ```

#### Streamlit Issues
- **Error**: "Port 8501 is already in use"
- **Solution**: Kill existing process or change port:
  ```bash
  # Kill process on port 8501
  lsof -ti:8501 | xargs kill -9
  
  # Or change port in start_app.py
  ```

### Debug Mode
Enable debug logging:
```bash
export LOG_LEVEL=DEBUG
python start_app.py
```

### Performance Monitoring
View performance metrics in the web interface or check logs for detailed timing information.

## ğŸ¤ Contributing
1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests for new functionality
5. Run the test suite
6. Submit a pull request

## ğŸ“ License
This project is developed for educational and research purposes.

## ğŸ™ Acknowledgments
- OpenAI for GPT models and APIs
- Hugging Face for transformer models and sentence-transformers
- Streamlit for the web interface framework
- FAISS for efficient vector similarity search
- The open-source community for various libraries and tools

## ğŸ“š Additional Documentation
- **ARCHITECTURE.md**: Detailed system architecture and design patterns
- **MEMORY_SYSTEM.md**: Memory system implementation details
- **CHANGELOG.md**: Version history and changes
- **docs/**: Additional technical documentation
